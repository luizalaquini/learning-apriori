{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1  2          3\n",
       "0  1  1193  5  978300760\n",
       "1  1   661  3  978302109\n",
       "2  1   914  3  978301968\n",
       "3  1  3408  4  978300275\n",
       "4  1  2355  5  978824291"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the ratings data\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat',\\\n",
    "          sep=\"::\", header = None, engine='python')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3943</th>\n",
       "      <th>3944</th>\n",
       "      <th>3945</th>\n",
       "      <th>3946</th>\n",
       "      <th>3947</th>\n",
       "      <th>3948</th>\n",
       "      <th>3949</th>\n",
       "      <th>3950</th>\n",
       "      <th>3951</th>\n",
       "      <th>3952</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "1  1     2     3     4     5     6     7     8     9     10    ...  3943  \\\n",
       "0                                                              ...         \n",
       "1   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "5   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "1  3944  3945  3946  3947  3948  3949  3950  3951  3952  \n",
       "0                                                        \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3706 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets pivot the data to get it at a user level\n",
    "data_df = pd.pivot_table(ratings[[0,1,2]],\\\n",
    "          values=2, index=0, columns=1 ).fillna(0)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_0</th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "      <th>item_5</th>\n",
       "      <th>item_6</th>\n",
       "      <th>item_7</th>\n",
       "      <th>item_8</th>\n",
       "      <th>item_9</th>\n",
       "      <th>...</th>\n",
       "      <th>item_490</th>\n",
       "      <th>item_491</th>\n",
       "      <th>item_492</th>\n",
       "      <th>item_493</th>\n",
       "      <th>item_494</th>\n",
       "      <th>item_495</th>\n",
       "      <th>item_496</th>\n",
       "      <th>item_497</th>\n",
       "      <th>item_498</th>\n",
       "      <th>item_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455657</td>\n",
       "      <td>0.620133</td>\n",
       "      <td>0.277381</td>\n",
       "      <td>0.188121</td>\n",
       "      <td>0.463698</td>\n",
       "      <td>0.353352</td>\n",
       "      <td>0.583656</td>\n",
       "      <td>0.077735</td>\n",
       "      <td>0.974395</td>\n",
       "      <td>0.986211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698162</td>\n",
       "      <td>0.536096</td>\n",
       "      <td>0.309528</td>\n",
       "      <td>0.813795</td>\n",
       "      <td>0.684731</td>\n",
       "      <td>0.162617</td>\n",
       "      <td>0.910927</td>\n",
       "      <td>0.822537</td>\n",
       "      <td>0.949800</td>\n",
       "      <td>0.725720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799416</td>\n",
       "      <td>0.694696</td>\n",
       "      <td>0.272145</td>\n",
       "      <td>0.590231</td>\n",
       "      <td>0.360974</td>\n",
       "      <td>0.091582</td>\n",
       "      <td>0.917314</td>\n",
       "      <td>0.136819</td>\n",
       "      <td>0.950237</td>\n",
       "      <td>0.446006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185133</td>\n",
       "      <td>0.541901</td>\n",
       "      <td>0.872946</td>\n",
       "      <td>0.732225</td>\n",
       "      <td>0.806561</td>\n",
       "      <td>0.658783</td>\n",
       "      <td>0.692277</td>\n",
       "      <td>0.849196</td>\n",
       "      <td>0.249668</td>\n",
       "      <td>0.489425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237544</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.227270</td>\n",
       "      <td>0.073196</td>\n",
       "      <td>0.603449</td>\n",
       "      <td>0.668213</td>\n",
       "      <td>0.619490</td>\n",
       "      <td>0.463494</td>\n",
       "      <td>0.379786</td>\n",
       "      <td>0.863334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.519082</td>\n",
       "      <td>0.479182</td>\n",
       "      <td>0.025642</td>\n",
       "      <td>0.341248</td>\n",
       "      <td>0.380196</td>\n",
       "      <td>0.398823</td>\n",
       "      <td>0.580172</td>\n",
       "      <td>0.533603</td>\n",
       "      <td>0.607905</td>\n",
       "      <td>0.764883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765513</td>\n",
       "      <td>0.158908</td>\n",
       "      <td>0.610225</td>\n",
       "      <td>0.135354</td>\n",
       "      <td>0.751375</td>\n",
       "      <td>0.656955</td>\n",
       "      <td>0.956615</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.057055</td>\n",
       "      <td>0.282187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.261706</td>\n",
       "      <td>0.246979</td>\n",
       "      <td>0.906255</td>\n",
       "      <td>0.249546</td>\n",
       "      <td>0.271950</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>0.449740</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>0.487571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285784</td>\n",
       "      <td>0.203223</td>\n",
       "      <td>0.761798</td>\n",
       "      <td>0.386541</td>\n",
       "      <td>0.511275</td>\n",
       "      <td>0.492325</td>\n",
       "      <td>0.577279</td>\n",
       "      <td>0.865577</td>\n",
       "      <td>0.980739</td>\n",
       "      <td>0.407584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.119716</td>\n",
       "      <td>0.301410</td>\n",
       "      <td>0.163965</td>\n",
       "      <td>0.261691</td>\n",
       "      <td>0.126138</td>\n",
       "      <td>0.059495</td>\n",
       "      <td>0.674850</td>\n",
       "      <td>0.809887</td>\n",
       "      <td>0.954444</td>\n",
       "      <td>0.385121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185042</td>\n",
       "      <td>0.907333</td>\n",
       "      <td>0.383251</td>\n",
       "      <td>0.112915</td>\n",
       "      <td>0.954184</td>\n",
       "      <td>0.291942</td>\n",
       "      <td>0.036909</td>\n",
       "      <td>0.966182</td>\n",
       "      <td>0.954838</td>\n",
       "      <td>0.694163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.267215</td>\n",
       "      <td>0.176615</td>\n",
       "      <td>0.835887</td>\n",
       "      <td>0.404111</td>\n",
       "      <td>0.481017</td>\n",
       "      <td>0.344779</td>\n",
       "      <td>0.678286</td>\n",
       "      <td>0.271478</td>\n",
       "      <td>0.062304</td>\n",
       "      <td>0.042079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394545</td>\n",
       "      <td>0.786379</td>\n",
       "      <td>0.362930</td>\n",
       "      <td>0.054260</td>\n",
       "      <td>0.530885</td>\n",
       "      <td>0.136017</td>\n",
       "      <td>0.751096</td>\n",
       "      <td>0.735454</td>\n",
       "      <td>0.667888</td>\n",
       "      <td>0.468211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.258813</td>\n",
       "      <td>0.174448</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.940249</td>\n",
       "      <td>0.216489</td>\n",
       "      <td>0.314816</td>\n",
       "      <td>0.747976</td>\n",
       "      <td>0.407415</td>\n",
       "      <td>0.339505</td>\n",
       "      <td>0.910091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808109</td>\n",
       "      <td>0.734749</td>\n",
       "      <td>0.723624</td>\n",
       "      <td>0.536112</td>\n",
       "      <td>0.824388</td>\n",
       "      <td>0.300727</td>\n",
       "      <td>0.867356</td>\n",
       "      <td>0.626426</td>\n",
       "      <td>0.484527</td>\n",
       "      <td>0.580526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.578663</td>\n",
       "      <td>0.989142</td>\n",
       "      <td>0.329159</td>\n",
       "      <td>0.855647</td>\n",
       "      <td>0.026532</td>\n",
       "      <td>0.862262</td>\n",
       "      <td>0.667397</td>\n",
       "      <td>0.247983</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>0.905783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703674</td>\n",
       "      <td>0.206627</td>\n",
       "      <td>0.564155</td>\n",
       "      <td>0.330331</td>\n",
       "      <td>0.421515</td>\n",
       "      <td>0.442666</td>\n",
       "      <td>0.879735</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>0.818791</td>\n",
       "      <td>0.620621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.486359</td>\n",
       "      <td>0.065599</td>\n",
       "      <td>0.744274</td>\n",
       "      <td>0.458011</td>\n",
       "      <td>0.281923</td>\n",
       "      <td>0.144494</td>\n",
       "      <td>0.079979</td>\n",
       "      <td>0.176806</td>\n",
       "      <td>0.904032</td>\n",
       "      <td>0.057835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213876</td>\n",
       "      <td>0.822076</td>\n",
       "      <td>0.705511</td>\n",
       "      <td>0.765023</td>\n",
       "      <td>0.964082</td>\n",
       "      <td>0.665520</td>\n",
       "      <td>0.989442</td>\n",
       "      <td>0.487741</td>\n",
       "      <td>0.664987</td>\n",
       "      <td>0.626668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_0    item_1    item_2    item_3    item_4    item_5    item_6  \\\n",
       "0    0.374540  0.950714  0.731994  0.598658  0.156019  0.155995  0.058084   \n",
       "1    0.698162  0.536096  0.309528  0.813795  0.684731  0.162617  0.910927   \n",
       "2    0.185133  0.541901  0.872946  0.732225  0.806561  0.658783  0.692277   \n",
       "3    0.519082  0.479182  0.025642  0.341248  0.380196  0.398823  0.580172   \n",
       "4    0.261706  0.246979  0.906255  0.249546  0.271950  0.759398  0.449740   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.119716  0.301410  0.163965  0.261691  0.126138  0.059495  0.674850   \n",
       "996  0.267215  0.176615  0.835887  0.404111  0.481017  0.344779  0.678286   \n",
       "997  0.258813  0.174448  0.836308  0.940249  0.216489  0.314816  0.747976   \n",
       "998  0.578663  0.989142  0.329159  0.855647  0.026532  0.862262  0.667397   \n",
       "999  0.486359  0.065599  0.744274  0.458011  0.281923  0.144494  0.079979   \n",
       "\n",
       "       item_7    item_8    item_9  ...  item_490  item_491  item_492  \\\n",
       "0    0.866176  0.601115  0.708073  ...  0.455657  0.620133  0.277381   \n",
       "1    0.822537  0.949800  0.725720  ...  0.799416  0.694696  0.272145   \n",
       "2    0.849196  0.249668  0.489425  ...  0.237544  0.373252  0.227270   \n",
       "3    0.533603  0.607905  0.764883  ...  0.765513  0.158908  0.610225   \n",
       "4    0.776711  0.065366  0.487571  ...  0.285784  0.203223  0.761798   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995  0.809887  0.954444  0.385121  ...  0.185042  0.907333  0.383251   \n",
       "996  0.271478  0.062304  0.042079  ...  0.394545  0.786379  0.362930   \n",
       "997  0.407415  0.339505  0.910091  ...  0.808109  0.734749  0.723624   \n",
       "998  0.247983  0.028812  0.905783  ...  0.703674  0.206627  0.564155   \n",
       "999  0.176806  0.904032  0.057835  ...  0.213876  0.822076  0.705511   \n",
       "\n",
       "     item_493  item_494  item_495  item_496  item_497  item_498  item_499  \n",
       "0    0.188121  0.463698  0.353352  0.583656  0.077735  0.974395  0.986211  \n",
       "1    0.590231  0.360974  0.091582  0.917314  0.136819  0.950237  0.446006  \n",
       "2    0.073196  0.603449  0.668213  0.619490  0.463494  0.379786  0.863334  \n",
       "3    0.135354  0.751375  0.656955  0.956615  0.068958  0.057055  0.282187  \n",
       "4    0.386541  0.511275  0.492325  0.577279  0.865577  0.980739  0.407584  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  0.112915  0.954184  0.291942  0.036909  0.966182  0.954838  0.694163  \n",
       "996  0.054260  0.530885  0.136017  0.751096  0.735454  0.667888  0.468211  \n",
       "997  0.536112  0.824388  0.300727  0.867356  0.626426  0.484527  0.580526  \n",
       "998  0.330331  0.421515  0.442666  0.879735  0.009206  0.818791  0.620621  \n",
       "999  0.765023  0.964082  0.665520  0.989442  0.487741  0.664987  0.626668  \n",
       "\n",
       "[1000 rows x 500 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Function to generate synthetic user-item interaction data\n",
    "def generate_synthetic_data(num_users, num_items):\n",
    "    np.random.seed(42)  # Set the seed for reproducibility\n",
    "    data = np.random.rand(num_users, num_items)  # Generate random data\n",
    "    df = pd.DataFrame(data, columns=[f'item_{i}' for i in range(num_items)])\n",
    "    return df\n",
    "\n",
    "# Generate synthetic data for 1000 users and 500 items\n",
    "num_users = 1000\n",
    "num_items = 500\n",
    "data_df = generate_synthetic_data(num_users, num_items)\n",
    "\n",
    "data_df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [3., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert DataFrame to NumPy array\n",
    "data = data_df.to_numpy()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model with input, hidden, encoding, hidden, and output layers\n",
    "input_dim = data.shape[1]  # Number of items\n",
    "encoding_dim = 64  # Number of neurons in the bottleneck layer\n",
    "hidden_dim = 128   # Number of neurons in the hidden layers\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# First hidden layer\n",
    "hidden_layer1 = Dense(hidden_dim, activation='relu')(input_layer)\n",
    "\n",
    "# Encoding layer (bottleneck layer)\n",
    "encoder = Dense(encoding_dim, activation='relu')(hidden_layer1)\n",
    "\n",
    "# Second hidden layer\n",
    "hidden_layer2 = Dense(hidden_dim, activation='relu')(encoder)\n",
    "\n",
    "# Output layer\n",
    "decoder = Dense(input_dim, activation='sigmoid')(hidden_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.1725 - val_loss: 0.8879\n",
      "Epoch 2/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9951 - val_loss: 0.8772\n",
      "Epoch 3/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9977 - val_loss: 0.8641\n",
      "Epoch 4/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0124 - val_loss: 0.8528\n",
      "Epoch 5/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9204 - val_loss: 0.8421\n",
      "Epoch 6/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9337 - val_loss: 0.8354\n",
      "Epoch 7/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9363 - val_loss: 0.8304\n",
      "Epoch 8/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9110 - val_loss: 0.8268\n",
      "Epoch 9/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9340 - val_loss: 0.8237\n",
      "Epoch 10/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9041 - val_loss: 0.8217\n",
      "Epoch 11/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9290 - val_loss: 0.8198\n",
      "Epoch 12/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8762 - val_loss: 0.8182\n",
      "Epoch 13/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8915 - val_loss: 0.8172\n",
      "Epoch 14/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8900 - val_loss: 0.8161\n",
      "Epoch 15/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8936 - val_loss: 0.8151\n",
      "Epoch 16/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8896 - val_loss: 0.8144\n",
      "Epoch 17/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8972 - val_loss: 0.8137\n",
      "Epoch 18/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9489 - val_loss: 0.8132\n",
      "Epoch 19/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8875 - val_loss: 0.8129\n",
      "Epoch 20/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8913 - val_loss: 0.8124\n",
      "Epoch 21/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8929 - val_loss: 0.8122\n",
      "Epoch 22/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9135 - val_loss: 0.8118\n",
      "Epoch 23/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8742 - val_loss: 0.8116\n",
      "Epoch 24/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8508 - val_loss: 0.8112\n",
      "Epoch 25/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8711 - val_loss: 0.8112\n",
      "Epoch 26/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8414 - val_loss: 0.8111\n",
      "Epoch 27/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8705 - val_loss: 0.8111\n",
      "Epoch 28/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8766 - val_loss: 0.8111\n",
      "Epoch 29/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9291 - val_loss: 0.8109\n",
      "Epoch 30/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8904 - val_loss: 0.8108\n",
      "Epoch 31/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8711 - val_loss: 0.8109\n",
      "Epoch 32/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8746 - val_loss: 0.8109\n",
      "Epoch 33/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8754 - val_loss: 0.8109\n",
      "Epoch 34/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8615 - val_loss: 0.8108\n",
      "Epoch 35/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8421 - val_loss: 0.8109\n",
      "Epoch 36/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8555 - val_loss: 0.8108\n",
      "Epoch 37/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8447 - val_loss: 0.8109\n",
      "Epoch 38/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8768 - val_loss: 0.8107\n",
      "Epoch 39/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8632 - val_loss: 0.8108\n",
      "Epoch 40/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8767 - val_loss: 0.8109\n",
      "Epoch 41/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8440 - val_loss: 0.8107\n",
      "Epoch 42/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8279 - val_loss: 0.8107\n",
      "Epoch 43/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8836 - val_loss: 0.8109\n",
      "Epoch 44/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8273 - val_loss: 0.8108\n",
      "Epoch 45/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8658 - val_loss: 0.8111\n",
      "Epoch 46/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8903 - val_loss: 0.8109\n",
      "Epoch 47/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8929 - val_loss: 0.8111\n",
      "Epoch 48/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9013 - val_loss: 0.8112\n",
      "Epoch 49/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8725 - val_loss: 0.8111\n",
      "Epoch 50/50\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8365 - val_loss: 0.8113\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build the autoencoder model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# Compile the model with Adam optimizer and Mean Squared Error loss\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "autoencoder.fit(train_data, train_data,\n",
    "                epochs=50,  # Number of epochs\n",
    "                batch_size=256,  # Batch size\n",
    "                shuffle=True,  # Shuffle the data\n",
    "                validation_data=(test_data, test_data))  # Use test data for validation\n",
    "\n",
    "# Extract the encoder part of the autoencoder to get the encoded representations\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
    "encoded_data = encoder_model.predict(data)\n",
    "\n",
    "# Define the decoder model\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer1 = autoencoder.layers[-2](encoded_input)  # Second hidden layer\n",
    "decoder_output = autoencoder.layers[-1](decoder_layer1)  # Output layer\n",
    "decoder_model = Model(inputs=encoded_input, outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend items for a given user based on encoded data\n",
    "def recommend_items(user_id, num_recommendations=5):\n",
    "    user_vector = encoded_data[user_id].reshape(1, -1)  # Get the encoded vector for the user\n",
    "    reconstructed_user = decoder_model.predict(user_vector)  # Reconstruct the user vector using the decoder\n",
    "    # Sort the items by predicted score in descending order and get the top recommendations\n",
    "    recommended_items = np.argsort(reconstructed_user[0])[::-1][:num_recommendations]\n",
    "    return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Recommended movies for user 10: [3029  101 1398 1743  174]\n"
     ]
    }
   ],
   "source": [
    "# Example: Get recommendations for user with ID \n",
    "user_id = 10\n",
    "recommendations = recommend_items(user_id)\n",
    "print(f\"Recommended movies for user {user_id}: {recommendations}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
